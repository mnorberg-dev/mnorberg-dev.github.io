<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Engineering on Matthew Norberg&#39;s Data Engineering Blog</title>
    <link>http://localhost:1313/tags/data-engineering/</link>
    <description>Recent content in Data Engineering on Matthew Norberg&#39;s Data Engineering Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <managingEditor>mattnorberg4@gmail.com (Matthew Norberg)</managingEditor>
    <webMaster>mattnorberg4@gmail.com (Matthew Norberg)</webMaster>
    <copyright>© 2026 Matthew Norberg</copyright>
    <lastBuildDate>Sun, 08 Feb 2026 00:00:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/data-engineering/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>The Hidden Cost of Databricks AI Agent Redeploys</title>
      <link>http://localhost:1313/posts/ai-agent-cost-savings/</link>
      <pubDate>Sun, 08 Feb 2026 00:00:00 +0000</pubDate>
      <author>mattnorberg4@gmail.com (Matthew Norberg)</author>
      <guid>http://localhost:1313/posts/ai-agent-cost-savings/</guid>
      <description>Redeploying AI agents in Databricks can quietly increase serving costs in ways that aren’t immediately obvious. Each call to &lt;code&gt;agents.deploy()&lt;/code&gt; creates a new agent version, and even versions receiving 0% of traffic may still consume compute resources. In this post, I walk through how we uncovered this behavior, the hypotheses we tested, and the experiment that confirmed it. Cleaning up unused agent versions ultimately reduced our serving costs by roughly 50%.</description>
      
    </item>
    
    <item>
      <title>Creating AI Processing Pipelines: A Data-First Approach</title>
      <link>http://localhost:1313/posts/inference-table-processing-tests/</link>
      <pubDate>Wed, 17 Dec 2025 00:00:00 +0000</pubDate>
      <author>mattnorberg4@gmail.com (Matthew Norberg)</author>
      <guid>http://localhost:1313/posts/inference-table-processing-tests/</guid>
      <description>Databricks Mosaic AI Gateway captures rich AI agent request and response data, but not in a format suitable for analysis. Turning that data into insights requires processing pipelines, and before building them, you need to understand the different shapes inference data can take. This post argues for a data-first approach that intentionally generates and examines real inference cases before designing pipelines that have to survive production.</description>
      
    </item>
    
  </channel>
</rss>
